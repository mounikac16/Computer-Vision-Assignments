{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assign3_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.5"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "code",
        "id": "rquheDGHE62b",
        "outputId": "f1a0fbc9-186b-46e0-e742-0092791644a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2ArwUCVevN1c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "w8MW8GYrFAej",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import scipy\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import torchvision.transforms.functional as TF\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import io as sio\n",
        "from scipy import ndimage, misc\n",
        "import csv\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "nlAFAGgMJkW9",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_dir = \"ResNet18_data/train\"\n",
        "\n",
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
        "model_name = \"alexnet\"\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 8\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 8\n",
        "\n",
        "# Number of epochs to train for\n",
        "num_epochs = 15\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Xp4mCMAEZ9ya",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_images(images_path, number_of_images):\n",
        "  images = []\n",
        "  for i in range(number_of_images):\n",
        "    print(i+1)\n",
        "    path = images_path + '/' + str(i+1) + '.jpg'\n",
        "    image = scipy.misc.imread(path)\n",
        "    images.append(image)\n",
        "  images = np.array(images)\n",
        "  print(images.shape)\n",
        "  return images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ml56mttlaIae",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_labels(labels_path):\n",
        "\twith open(labels_path,'rU') as csvfile:\n",
        "\t\tcsvfile = csv.reader(csvfile, delimiter=',')\n",
        "\t\tcsvdata = list(csvfile)\n",
        "\t\tlabels = map(int, csvdata[0])\n",
        "\t\treturn list(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wFlYPG5kaTVy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train_images_path = '/content/drive/My Drive/cv_assign3_dataset/train'\n",
        "# train_images = read_images(train_images_path, 1888)\n",
        "# train_images.shape\n",
        "# train_labels_path = '/content/drive/My Drive/cv_assign3_dataset/train_labels.csv'\n",
        "# train_labels = read_labels(train_labels_path)\n",
        "# print(len(train_labels))\n",
        "# # print train_labels\n",
        "\n",
        "# test_images_path = '/content/drive/My Drive/cv_assign3_dataset/test'\n",
        "# test_images = read_images(test_images_path, 800)\n",
        "# test_images.shape\n",
        "# test_labels_path = '/content/drive/My Drive/cv_assign3_dataset/test_labels.csv'\n",
        "# test_labels = read_labels(test_labels_path)\n",
        "# print(len(test_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NCvhnrzFKN-v",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9cWpIhbVKePR",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mjZUWUrCKWN_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pKIH1iaXFQ5I",
        "outputId": "fafca5da-61a2-4855-8070-cdbeb48db986",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "alexnet = models.alexnet(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /root/.torch/models/alexnet-owt-4df8aa71.pth\n",
            "244418560it [00:08, 29397727.17it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "_yEtxHRCFU0h",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "alexnet.classifier[6] = nn.Linear(4096,8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tyYL5ghCFU8T",
        "outputId": "f5a11269-b0fd-48d2-d4bd-0e57ac12282c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        }
      },
      "cell_type": "code",
      "source": [
        "alexnet.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace)\n",
              "    (3): Dropout(p=0.5)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace)\n",
              "    (6): Linear(in_features=4096, out_features=8, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JmFtVP2UFVBz",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"squeezenet\":\n",
        "        \"\"\" Squeezenet\n",
        "        \"\"\"\n",
        "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "        model_ft.num_classes = num_classes\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"inception\":\n",
        "        \"\"\" Inception v3\n",
        "        Be careful, expects (299,299) sized images and has auxiliary output\n",
        "        \"\"\"\n",
        "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        # Handle the auxilary net\n",
        "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        # Handle the primary net\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 299\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QP33rGDu8SXs",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_labels = np.array(pd.read_csv('/content/drive/My Drive/ResNet18_data/train_labels.csv',header=None))[0]\n",
        "test_labels = np.array(pd.read_csv('/content/drive/My Drive/ResNet18_data/test_labels.csv',header=None))[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-kvz5g4XTbDj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class FaceLandmarksDataset(Dataset):\n",
        "    \"\"\"Face Landmarks dataset.\"\"\"\n",
        "\n",
        "    def __init__(self,root_dir,total_count, csv_file, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.total_count = total_count\n",
        "        self.csv_file = np.array(pd.read_csv(csv_file,header=None))[0]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.total_count\n",
        "\n",
        "    def __getitem__(self, image_no):\n",
        "        img_name = os.path.join(self.root_dir,\n",
        "                                str(image_no+1)+\".jpg\")\n",
        "        image = Image.open(img_name)\n",
        "        sample = {'image': image, 'label': self.csv_file[image_no]-1}\n",
        "\n",
        "        if self.transform:\n",
        "            sample['image'] = self.transform(sample['image'])\n",
        "\n",
        "        return sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "d-KdkZBEUBcD",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainDataset = FaceLandmarksDataset('/content/drive/My Drive/ResNet18_data/train',1888,'/content/drive/My Drive/ResNet18_data/train_labels.csv',transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]))\n",
        "\n",
        "testDataset = FaceLandmarksDataset('/content/drive/My Drive/ResNet18_data/test',800,'/content/drive/My Drive/ResNet18_data/test_labels.csv',transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "vQPso0kxU2dG",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "q6JbuZhCFVF6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(\"alexnet\", 8, feature_extract, use_pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QMEIBcT2I_vM",
        "outputId": "c9b933c8-0950-47fd-a8a7-7d136bbedb9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        }
      },
      "cell_type": "code",
      "source": [
        "# Print the model we just instantiated\n",
        "print(model_ft)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Dropout(p=0.5)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace)\n",
            "    (6): Linear(in_features=4096, out_features=8, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bR2cb0R_Lc9T",
        "outputId": "e61ca926-0456-49e9-c8f1-b56cf7ff89fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Initializing Datasets and Dataloaders...\")\n",
        "\n",
        "trainDataloader = torch.utils.data.DataLoader(trainDataset,batch_size = 8, shuffle = True, num_workers=4)\n",
        "testDataloader = torch.utils.data.DataLoader(testDataset,batch_size = 8, shuffle = True, num_workers=4)\n",
        "Dataloaders_dict = {trainDataloader,testDataloader}\n",
        "# Detect if we have a GPU available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing Datasets and Dataloaders...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mI4GhKz9O93b",
        "outputId": "d4f61774-353e-4e70-ff5d-844f7f348ec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "# Send the model to GPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t classifier.6.weight\n",
            "\t classifier.6.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dIsa0YHRV1ro",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Setup the loss fxn\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train and evaluate\n",
        "#model_ft, hist = train_model(model_ft,trainDataloader,testDataloader, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"alexnet\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wAGSFgIrLwCd",
        "outputId": "e2384663-c045-4ab3-8bbd-7395c6000832",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4214
        }
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainDataloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data['image'],data['label']\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # zero the parameter gradients\n",
        "        optimizer_ft.zero_grad()\n",
        "        outputs = model_ft(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer_ft.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 10 == 9:    # print every 10 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 10))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    10] loss: 0.247\n",
            "[1,    20] loss: 0.233\n",
            "[1,    30] loss: 0.434\n",
            "[1,    40] loss: 0.205\n",
            "[1,    50] loss: 0.311\n",
            "[1,    60] loss: 0.126\n",
            "[1,    70] loss: 0.634\n",
            "[1,    80] loss: 0.210\n",
            "[1,    90] loss: 0.247\n",
            "[1,   100] loss: 0.519\n",
            "[1,   110] loss: 0.418\n",
            "[1,   120] loss: 0.156\n",
            "[1,   130] loss: 0.474\n",
            "[1,   140] loss: 0.244\n",
            "[1,   150] loss: 0.479\n",
            "[1,   160] loss: 0.178\n",
            "[1,   170] loss: 0.221\n",
            "[1,   180] loss: 0.376\n",
            "[1,   190] loss: 0.354\n",
            "[1,   200] loss: 0.294\n",
            "[1,   210] loss: 0.163\n",
            "[1,   220] loss: 0.107\n",
            "[1,   230] loss: 0.381\n",
            "[2,    10] loss: 0.526\n",
            "[2,    20] loss: 0.400\n",
            "[2,    30] loss: 0.176\n",
            "[2,    40] loss: 0.216\n",
            "[2,    50] loss: 0.333\n",
            "[2,    60] loss: 0.182\n",
            "[2,    70] loss: 0.530\n",
            "[2,    80] loss: 0.281\n",
            "[2,    90] loss: 0.404\n",
            "[2,   100] loss: 0.237\n",
            "[2,   110] loss: 0.280\n",
            "[2,   120] loss: 0.286\n",
            "[2,   130] loss: 0.268\n",
            "[2,   140] loss: 0.464\n",
            "[2,   150] loss: 0.236\n",
            "[2,   160] loss: 0.293\n",
            "[2,   170] loss: 0.358\n",
            "[2,   180] loss: 0.270\n",
            "[2,   190] loss: 0.302\n",
            "[2,   200] loss: 0.252\n",
            "[2,   210] loss: 0.288\n",
            "[2,   220] loss: 0.265\n",
            "[2,   230] loss: 0.275\n",
            "[3,    10] loss: 0.235\n",
            "[3,    20] loss: 0.436\n",
            "[3,    30] loss: 0.195\n",
            "[3,    40] loss: 0.207\n",
            "[3,    50] loss: 0.213\n",
            "[3,    60] loss: 0.298\n",
            "[3,    70] loss: 0.138\n",
            "[3,    80] loss: 0.289\n",
            "[3,    90] loss: 0.349\n",
            "[3,   100] loss: 0.179\n",
            "[3,   110] loss: 0.261\n",
            "[3,   120] loss: 0.233\n",
            "[3,   130] loss: 0.282\n",
            "[3,   140] loss: 0.444\n",
            "[3,   150] loss: 0.308\n",
            "[3,   160] loss: 0.617\n",
            "[3,   170] loss: 0.316\n",
            "[3,   180] loss: 0.262\n",
            "[3,   190] loss: 0.690\n",
            "[3,   200] loss: 0.498\n",
            "[3,   210] loss: 0.245\n",
            "[3,   220] loss: 0.346\n",
            "[3,   230] loss: 0.197\n",
            "[4,    10] loss: 0.305\n",
            "[4,    20] loss: 0.264\n",
            "[4,    30] loss: 0.243\n",
            "[4,    40] loss: 0.232\n",
            "[4,    50] loss: 0.170\n",
            "[4,    60] loss: 0.165\n",
            "[4,    70] loss: 0.413\n",
            "[4,    80] loss: 0.267\n",
            "[4,    90] loss: 0.443\n",
            "[4,   100] loss: 0.189\n",
            "[4,   110] loss: 0.424\n",
            "[4,   120] loss: 0.257\n",
            "[4,   130] loss: 0.297\n",
            "[4,   140] loss: 0.148\n",
            "[4,   150] loss: 0.213\n",
            "[4,   160] loss: 0.302\n",
            "[4,   170] loss: 0.283\n",
            "[4,   180] loss: 0.693\n",
            "[4,   190] loss: 0.186\n",
            "[4,   200] loss: 0.539\n",
            "[4,   210] loss: 0.322\n",
            "[4,   220] loss: 0.360\n",
            "[4,   230] loss: 0.376\n",
            "[5,    10] loss: 0.255\n",
            "[5,    20] loss: 0.490\n",
            "[5,    30] loss: 0.260\n",
            "[5,    40] loss: 0.270\n",
            "[5,    50] loss: 0.248\n",
            "[5,    60] loss: 0.387\n",
            "[5,    70] loss: 0.301\n",
            "[5,    80] loss: 0.496\n",
            "[5,    90] loss: 0.332\n",
            "[5,   100] loss: 0.312\n",
            "[5,   110] loss: 0.542\n",
            "[5,   120] loss: 0.295\n",
            "[5,   130] loss: 0.287\n",
            "[5,   140] loss: 0.433\n",
            "[5,   150] loss: 0.132\n",
            "[5,   160] loss: 0.203\n",
            "[5,   170] loss: 0.255\n",
            "[5,   180] loss: 0.369\n",
            "[5,   190] loss: 0.262\n",
            "[5,   200] loss: 0.239\n",
            "[5,   210] loss: 0.342\n",
            "[5,   220] loss: 0.350\n",
            "[5,   230] loss: 0.693\n",
            "[6,    10] loss: 0.356\n",
            "[6,    20] loss: 0.299\n",
            "[6,    30] loss: 0.269\n",
            "[6,    40] loss: 0.175\n",
            "[6,    50] loss: 0.380\n",
            "[6,    60] loss: 0.372\n",
            "[6,    70] loss: 0.500\n",
            "[6,    80] loss: 0.103\n",
            "[6,    90] loss: 0.359\n",
            "[6,   100] loss: 0.348\n",
            "[6,   110] loss: 0.261\n",
            "[6,   120] loss: 0.576\n",
            "[6,   130] loss: 0.331\n",
            "[6,   140] loss: 0.319\n",
            "[6,   150] loss: 0.235\n",
            "[6,   160] loss: 0.251\n",
            "[6,   170] loss: 0.216\n",
            "[6,   180] loss: 0.201\n",
            "[6,   190] loss: 0.304\n",
            "[6,   200] loss: 0.146\n",
            "[6,   210] loss: 0.254\n",
            "[6,   220] loss: 0.331\n",
            "[6,   230] loss: 0.341\n",
            "[7,    10] loss: 0.088\n",
            "[7,    20] loss: 0.276\n",
            "[7,    30] loss: 0.310\n",
            "[7,    40] loss: 0.558\n",
            "[7,    50] loss: 0.454\n",
            "[7,    60] loss: 0.377\n",
            "[7,    70] loss: 0.262\n",
            "[7,    80] loss: 0.378\n",
            "[7,    90] loss: 0.275\n",
            "[7,   100] loss: 0.204\n",
            "[7,   110] loss: 0.190\n",
            "[7,   120] loss: 0.299\n",
            "[7,   130] loss: 0.256\n",
            "[7,   140] loss: 0.095\n",
            "[7,   150] loss: 0.296\n",
            "[7,   160] loss: 0.415\n",
            "[7,   170] loss: 0.327\n",
            "[7,   180] loss: 0.581\n",
            "[7,   190] loss: 0.216\n",
            "[7,   200] loss: 0.369\n",
            "[7,   210] loss: 0.397\n",
            "[7,   220] loss: 0.300\n",
            "[7,   230] loss: 0.381\n",
            "[8,    10] loss: 0.128\n",
            "[8,    20] loss: 0.208\n",
            "[8,    30] loss: 0.483\n",
            "[8,    40] loss: 0.228\n",
            "[8,    50] loss: 0.167\n",
            "[8,    60] loss: 0.188\n",
            "[8,    70] loss: 0.169\n",
            "[8,    80] loss: 0.266\n",
            "[8,    90] loss: 0.284\n",
            "[8,   100] loss: 0.362\n",
            "[8,   110] loss: 0.307\n",
            "[8,   120] loss: 0.230\n",
            "[8,   130] loss: 0.165\n",
            "[8,   140] loss: 0.165\n",
            "[8,   150] loss: 0.226\n",
            "[8,   160] loss: 0.533\n",
            "[8,   170] loss: 0.487\n",
            "[8,   180] loss: 0.355\n",
            "[8,   190] loss: 0.323\n",
            "[8,   200] loss: 0.269\n",
            "[8,   210] loss: 0.290\n",
            "[8,   220] loss: 0.296\n",
            "[8,   230] loss: 0.280\n",
            "[9,    10] loss: 0.207\n",
            "[9,    20] loss: 0.431\n",
            "[9,    30] loss: 0.449\n",
            "[9,    40] loss: 0.142\n",
            "[9,    50] loss: 0.123\n",
            "[9,    60] loss: 0.267\n",
            "[9,    70] loss: 0.343\n",
            "[9,    80] loss: 0.246\n",
            "[9,    90] loss: 0.301\n",
            "[9,   100] loss: 0.236\n",
            "[9,   110] loss: 0.316\n",
            "[9,   120] loss: 0.439\n",
            "[9,   130] loss: 0.315\n",
            "[9,   140] loss: 0.244\n",
            "[9,   150] loss: 0.129\n",
            "[9,   160] loss: 0.491\n",
            "[9,   170] loss: 0.225\n",
            "[9,   180] loss: 0.184\n",
            "[9,   190] loss: 0.544\n",
            "[9,   200] loss: 0.529\n",
            "[9,   210] loss: 0.231\n",
            "[9,   220] loss: 0.398\n",
            "[9,   230] loss: 0.433\n",
            "[10,    10] loss: 0.367\n",
            "[10,    20] loss: 0.246\n",
            "[10,    30] loss: 0.318\n",
            "[10,    40] loss: 0.157\n",
            "[10,    50] loss: 0.371\n",
            "[10,    60] loss: 0.278\n",
            "[10,    70] loss: 0.234\n",
            "[10,    80] loss: 0.086\n",
            "[10,    90] loss: 0.145\n",
            "[10,   100] loss: 0.334\n",
            "[10,   110] loss: 0.506\n",
            "[10,   120] loss: 0.362\n",
            "[10,   130] loss: 0.272\n",
            "[10,   140] loss: 0.461\n",
            "[10,   150] loss: 0.238\n",
            "[10,   160] loss: 0.200\n",
            "[10,   170] loss: 0.296\n",
            "[10,   180] loss: 0.352\n",
            "[10,   190] loss: 0.190\n",
            "[10,   200] loss: 0.288\n",
            "[10,   210] loss: 0.264\n",
            "[10,   220] loss: 0.346\n",
            "[10,   230] loss: 0.245\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "q-dUMiJ2V10T",
        "outputId": "6cee548f-4835-4197-9d3b-7dac56132635",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "running_loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.720498561859131"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6S6nMMA88gUz",
        "outputId": "efa3ffec-3f1c-4276-c3ca-12bb46a2856a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(testDataloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data['image'],data['label']\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model_ft(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        \n",
        "print('Accuracy of the network on the 800 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 800 test images: 90 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "RC5dstrM1yl2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}